---
name: "Clavix: PRD"
description: Clavix Planning Mode - Transform ideas into structured PRDs through strategic questioning
---

# Clavix: Create Your PRD

I'll help you create a solid Product Requirements Document through a few key questions. By the end, you'll have clear documentation of what to build and why.

---

## What This Does

When you run `/clavix-prd`, I:
1. **Ask strategic questions** - One at a time, so it's not overwhelming
2. **Help you think through details** - If something's vague, I'll probe deeper
3. **Create two PRD documents** - Full version and quick reference
4. **Check quality** - Make sure the PRD is clear enough for AI to work with

**This is about planning, not building yet.**

---

## CLAVIX MODE: Planning Only

**I'm in planning mode. Creating your PRD.**

**What I'll do:**
- âœ“ Guide you through strategic questions
- âœ“ Help clarify vague areas
- âœ“ Generate comprehensive PRD documents
- âœ“ Check that the PRD is AI-ready
- âœ“ Create both full and quick versions

**What I won't do:**
- âœ— Write code for the feature
- âœ— Start implementing anything
- âœ— Skip the planning questions

**We're documenting what to build, not building it.**

For complete mode documentation, see: `.clavix/instructions/core/clavix-mode.md`

---

## Self-Correction Protocol

**DETECT**: If you find yourself doing any of these 6 mistake types:

| Type | What It Looks Like |
|------|--------------------|
| 1. Implementation Code | Writing function/class definitions, creating components, generating API endpoints, test files, database schemas, or configuration files for the user's feature |
| 2. Skipping Strategic Questions | Not asking about problem, users, features, constraints, or success metrics |
| 3. Incomplete PRD Structure | Missing sections: problem statement, user needs, requirements, constraints |
| 4. No Quick PRD | Not generating the AI-optimized 2-3 paragraph version alongside full PRD |
| 5. Missing Task Breakdown | Not offering to generate tasks.md with actionable implementation tasks |
| 6. Capability Hallucination | Claiming features Clavix doesn't have, inventing workflows |

**STOP**: Immediately halt the incorrect action

**CORRECT**: Output:
"I apologize - I was [describe mistake]. Let me return to PRD development."

**RESUME**: Return to the PRD development workflow with strategic questioning.

---

## State Assertion (Required)

**Before starting PRD development, output:**
```
**CLAVIX MODE: PRD Development**
Mode: planning
Purpose: Guiding strategic questions to create comprehensive PRD documents
Implementation: BLOCKED - I will develop requirements, not implement the feature
```

---

## What is Clavix Planning Mode?

Clavix Planning Mode guides you through strategic questions to transform vague ideas into structured, comprehensive PRDs. The generated documents are:
- **Full PRD**: Comprehensive team-facing document
- **Quick PRD**: AI-optimized 2-3 paragraph version

Both documents are automatically validated for quality (Clarity, Structure, Completeness) to ensure they're ready for AI consumption.

## Instructions

1. Guide the user through these strategic questions, **one at a time** with validation:

   **Question 1**: What are we building and why? (Problem + goal in 2-3 sentences)

   - **Validation**: Must have both problem AND goal stated clearly
   - **If vague/short** (e.g., "a dashboard"): Ask probing questions:
     - "What specific problem does this dashboard solve?"
     - "Who will use this and what decisions will they make with it?"
     - "What happens if this doesn't exist?"
   - **If "I don't know"**: Ask:
     - "What triggered the need for this?"
     - "Can you describe the current pain point or opportunity?"
   - **Good answer example**: "Sales managers can't quickly identify at-risk deals in our 10K+ deal pipeline. Build a real-time dashboard showing deal health, top performers, and pipeline status so managers can intervene before deals are lost."

   **Question 2**: What are the must-have core features? (List 3-5 critical features)

   - **Validation**: At least 2 concrete features provided
   - **If vague** (e.g., "user management"): Probe deeper:
     - "What specific user management capabilities? (registration, roles, permissions, profile management?)"
     - "Which feature would you build first if you could only build one?"
   - **If too many** (7+ features): Help prioritize:
     - "If you had to launch with only 3 features, which would they be?"
     - "Which features are launch-blockers vs nice-to-have?"
   - **If "I don't know"**: Ask:
     - "Walk me through how someone would use this - what would they do first?"
     - "What's the core value this provides?"

   **Question 3**: Tech stack and requirements? (Technologies, integrations, constraints)

   - **Optional**: Can skip if extending existing project
   - **If vague** (e.g., "modern stack"): Probe:
     - "What technologies are already in use that this must integrate with?"
     - "Any specific frameworks or languages your team prefers?"
     - "Are there performance requirements (load time, concurrent users)?"
   - **If "I don't know"**: Suggest common stacks based on project type or skip

   **Question 4**: What is explicitly OUT of scope? (What are we NOT building?)

   - **Validation**: At least 1 explicit exclusion
   - **Why important**: Prevents scope creep and clarifies boundaries
   - **If stuck**: Suggest common exclusions:
     - "Are we building admin dashboards? Mobile apps? API integrations?"
     - "Are we handling payments? User authentication? Email notifications?"
   - **If "I don't know"**: Provide project-specific prompts based on previous answers

   **Question 5**: Any additional context or requirements?

   - **Optional**: Press Enter to skip
   - **Helpful areas**: Compliance needs, accessibility, localization, deadlines, team constraints

2. **Before proceeding to document generation**, verify minimum viable answers:
   - Q1: Both problem AND goal stated
   - Q2: At least 2 concrete features
   - Q4: At least 1 explicit scope exclusion
   - If missing critical info, ask targeted follow-ups

3. After collecting and validating all answers, generate TWO documents:

   **Full PRD** (comprehensive):
   ```markdown
   # Product Requirements Document: [Project Name]

   ## Problem & Goal
   [User's answer to Q1]

   ## Requirements
   ### Must-Have Features
   [User's answer to Q2, expanded with details]

   ### Technical Requirements
   [User's answer to Q3, detailed]

   ## Out of Scope
   [User's answer to Q4]

   ## Additional Context
   [User's answer to Q5 if provided]
   ```

   **Quick PRD** (2-3 paragraphs, AI-optimized):
   ```markdown
   [Concise summary combining problem, goal, and must-have features from Q1+Q2]

   [Technical requirements and constraints from Q3]

   [Out of scope and additional context from Q4+Q5]
   ```

3. **Save both documents** using the file-saving protocol below

4. **Quality Validation** (automatic):
   - After PRD generation, the quick-prd.md is analyzed for AI consumption quality
   - Assesses Clarity, Structure, and Completeness
   - Displays quality scores and improvement suggestions
   - Focus is on making PRDs actionable for AI agents

5. Display file paths, validation results, and suggest next steps.

## File-Saving Protocol (For AI Agents)

**As an AI agent, follow these exact steps to save PRD files:**

### Step 1: Determine Project Name
- **From user input**: Use project name mentioned during Q&A
- **If not specified**: Derive from problem/goal (sanitize: lowercase, spacesâ†’hyphens, remove special chars)
- **Example**: "Sales Manager Dashboard" â†’ `sales-manager-dashboard`

### Step 2: Create Output Directory
```bash
mkdir -p .clavix/outputs/{sanitized-project-name}
```

**Handle errors**:
- If directory creation fails: Check write permissions
- If `.clavix/` doesn't exist: Create it first: `mkdir -p .clavix/outputs/{project}`

### Step 3: Save Full PRD
**File path**: `.clavix/outputs/{project-name}/full-prd.md`

**Content structure**:
```markdown
# Product Requirements Document: {Project Name}

## Problem & Goal
{User's Q1 answer - problem and goal}

## Requirements
### Must-Have Features
{User's Q2 answer - expanded with details from conversation}

### Technical Requirements
{User's Q3 answer - tech stack, integrations, constraints}

## Out of Scope
{User's Q4 answer - explicit exclusions}

## Additional Context
{User's Q5 answer if provided, or omit section}

---

*Generated with Clavix Planning Mode*
*Generated: {ISO timestamp}*
```

### Step 4: Save Quick PRD
**File path**: `.clavix/outputs/{project-name}/quick-prd.md`

**Content structure** (2-3 paragraphs, AI-optimized):
```markdown
# {Project Name} - Quick PRD

{Paragraph 1: Combine problem + goal + must-have features from Q1+Q2}

{Paragraph 2: Technical requirements and constraints from Q3}

{Paragraph 3: Out of scope and additional context from Q4+Q5}

---

*Generated with Clavix Planning Mode*
*Generated: {ISO timestamp}*
```

### Step 5: Verify Files Were Created
```bash
ls .clavix/outputs/{project-name}/
```

**Expected output**:
- `full-prd.md`
- `quick-prd.md`

### Step 6: Communicate Success
Display to user:
```
âœ“ PRD generated successfully!

Files saved:
  â€¢ Full PRD: .clavix/outputs/{project-name}/full-prd.md
  â€¢ Quick PRD: .clavix/outputs/{project-name}/quick-prd.md

Quality Assessment:
  Clarity: {score}% - {feedback}
  Structure: {score}% - {feedback}
  Completeness: {score}% - {feedback}
  Overall: {score}%

Next steps:
  â€¢ Review and edit PRD files if needed
  â€¢ Run /clavix-plan to generate implementation tasks
```

### Error Handling

**If file write fails**:
1. Check error message
2. Common issues:
   - Permission denied: Inform user to check directory permissions
   - Disk full: Inform user about disk space
   - Path too long: Suggest shorter project name
3. Do NOT proceed to next steps without successful file save

**If directory already exists**:
- This is OK - proceed with writing files
- Existing files will be overwritten (user initiated PRD generation)
- If unsure: Ask user "Project `{name}` already exists. Overwrite PRD files?"

## Quality Validation

**What gets validated:**
- **Clarity**: Is the PRD clear and unambiguous for AI agents?
- **Structure**: Does information flow logically (context â†’ requirements â†’ constraints)?
- **Completeness**: Are all necessary specifications provided?

The validation ensures generated PRDs are immediately usable for AI consumption without back-and-forth clarifications.

## Workflow Navigation

**You are here:** Clavix Planning Mode (Strategic Planning)

**Common workflows:**
- **Full planning workflow**: `/clavix-prd` â†’ `/clavix-plan` â†’ `/clavix-implement` â†’ `/clavix-archive`
- **From deep mode**: `/clavix-deep` â†’ (strategic scope detected) â†’ `/clavix-prd`
- **Quick to strategic**: `/clavix-fast` â†’ (realizes complexity) â†’ `/clavix-prd`

**Related commands:**
- `/clavix-plan` - Generate task breakdown from PRD (next step)
- `/clavix-implement` - Execute tasks (after plan)
- `/clavix-summarize` - Alternative: Extract PRD from conversation instead of Q&A

## Tips

- Ask follow-up questions if answers are too vague
- Help users think through edge cases
- Keep the process conversational and supportive
- Generated PRDs are automatically validated for optimal AI consumption
- Clavix Planning Mode is designed for strategic features, not simple prompts

---

## Agent Transparency (v4.9)

### PRD Examples
## PRD Examples

Real examples of mini-PRDs to help users understand what good planning looks like.

---

### Example 1: Simple Mobile App

```markdown
# Mini-PRD: Habit Tracker App

## What We're Building
A mobile app that helps people build good habits without the guilt.
Unlike other trackers that shame you for breaking streaks, this one
celebrates your wins and keeps things positive.

## Who It's For
- People who've tried habit apps but felt judged
- Anyone who wants to build small daily habits
- People who prefer encouragement over pressure

## The Problem We're Solving
Most habit trackers use streaks and "don't break the chain" psychology.
When users miss a day, they feel like failures and often give up entirely.
We need an app that acknowledges life happens and celebrates progress
instead of perfection.

## Must-Have Features (v1)
1. **Add habits to track** - Simple creation with name and reminder time
2. **Mark habits complete** - One tap to check off
3. **Positive progress view** - "You've done this 15 times!" not "Day 3 of streak"
4. **Gentle reminders** - Optional notifications, easy to snooze
5. **Weekly celebration** - End-of-week summary highlighting wins

## Nice-to-Have Features (Later)
- Share progress with friends
- Habit insights and patterns
- Custom celebration messages
- Dark mode

## How We'll Know It's Working
- Users can add a habit in under 10 seconds
- App never shows negative language (no "streak broken")
- 70% of users who try it stick around for 2+ weeks
- Users report feeling "encouraged" in feedback

## Technical Approach
- React Native for iOS and Android
- Local storage for data (no account required)
- Simple, cheerful UI with soft colors
- Push notifications via device native APIs

## What's NOT In Scope
- Social features (v1 is personal only)
- Data export
- Web version
- Integrations with other apps
```

---

### Example 2: API/Backend Service

```markdown
# Mini-PRD: User Management API

## What We're Building
A REST API for managing users in our web application. Handles
registration, authentication, and user profiles with role-based
access control.

## Who It's For
- Frontend developers building our web app
- Admin team managing user accounts
- Other services that need user data

## The Problem We're Solving
Our current auth is scattered across multiple files with no clear
structure. We need a proper API that handles all user operations
in one place with consistent patterns.

## Must-Have Features (v1)
1. **User registration** - Email + password, email verification
2. **Authentication** - Login, logout, password reset
3. **JWT tokens** - Access (15min) + refresh (7 days)
4. **User profiles** - View and update own profile
5. **Role-based access** - Admin, Editor, Viewer levels
6. **Admin operations** - List users, change roles, disable accounts

## Nice-to-Have Features (Later)
- OAuth (Google, GitHub login)
- Two-factor authentication
- Audit logging
- API rate limiting per user

## How We'll Know It's Working
- All endpoints respond in under 100ms
- 100% test coverage on auth flows
- Zero security vulnerabilities in penetration testing
- Frontend team can integrate in under 1 day

## Technical Approach
- Node.js with Express framework
- PostgreSQL database
- JWT for auth tokens
- bcrypt for password hashing
- Jest for testing

## API Endpoints Overview
- POST /auth/register
- POST /auth/login
- POST /auth/logout
- POST /auth/refresh
- POST /auth/forgot-password
- GET/PUT /users/me
- GET /users (admin only)
- PUT /users/:id/role (admin only)

## What's NOT In Scope
- Frontend UI for auth
- Email service (will use existing)
- User analytics
- Multi-tenancy
```

---

### Example 3: Feature Addition

```markdown
# Mini-PRD: Search Feature for E-commerce Site

## What We're Building
A search feature that lets customers find products quickly. Should
be fast, relevant, and work well on mobile.

## Who It's For
- Customers shopping on our site
- Especially mobile users (60% of our traffic)
- People who know what they want and don't want to browse

## The Problem We're Solving
Customers are abandoning our site because they can't find products.
Current browse-only experience doesn't work when you have 5000+
products. We need search.

## Must-Have Features (v1)
1. **Search box** - Visible on every page, especially mobile
2. **Instant results** - Show results as user types
3. **Product cards** - Image, name, price in results
4. **Filters** - Category, price range, in-stock only
5. **No results page** - Helpful suggestions when search fails

## Nice-to-Have Features (Later)
- Search suggestions/autocomplete
- Recent searches
- "Did you mean?" for typos
- Voice search on mobile

## How We'll Know It's Working
- Results appear in under 200ms
- 80%+ of searches return relevant results
- Conversion rate from search > browse
- Mobile search usage > 30% of all searches

## Technical Approach
- Elasticsearch for search backend
- React components for UI
- Debounced search (300ms delay while typing)
- Server-side filtering for performance

## Integration Points
- Product database (PostgreSQL)
- Image CDN for product thumbnails
- Analytics for search tracking

## What's NOT In Scope
- Personalized results (same results for everyone)
- Search within categories (just global search)
- Advanced operators ("AND", "OR", quotes)
```

---

### Example 4: Internal Tool

```markdown
# Mini-PRD: Team Task Board

## What We're Building
A simple Kanban board for our team to track tasks. Think Trello
but just for us, without all the features we don't use.

## Who It's For
- Our development team (8 people)
- Project manager for oversight
- Occasionally stakeholders for status updates

## The Problem We're Solving
We're paying for Trello but only use 10% of it. Tasks get lost,
people forget to update cards, and it's overkill for our needs.
We want something simpler that fits how we actually work.

## Must-Have Features (v1)
1. **Three columns** - To Do, In Progress, Done
2. **Task cards** - Title, description, assignee
3. **Drag and drop** - Move cards between columns
4. **Comments** - Discuss tasks without leaving the board
5. **Slack notifications** - When tasks move or get assigned

## Nice-to-Have Features (Later)
- Due dates with reminders
- Labels/tags
- Multiple boards per project
- Time tracking

## How We'll Know It's Working
- Team adopts it within 1 week
- No tasks "fall through the cracks"
- Status meetings take 50% less time
- Nobody asks "what are you working on?"

## Technical Approach
- React frontend
- Node.js backend
- MongoDB for flexibility
- Socket.io for real-time updates
- Slack API integration

## What's NOT In Scope
- Mobile app (desktop only for now)
- Reporting/analytics
- Time tracking
- Multiple teams/permissions
```

---

### PRD Template (Blank)

Copy and fill in:

```markdown
# Mini-PRD: [Project Name]

## What We're Building
[1-2 sentences describing the product/feature]

## Who It's For
- [Primary user type]
- [Secondary user type]
- [Use case context]

## The Problem We're Solving
[What's the pain point? Why does this need to exist?]

## Must-Have Features (v1)
1. **[Feature]** - [Brief description]
2. **[Feature]** - [Brief description]
3. **[Feature]** - [Brief description]

## Nice-to-Have Features (Later)
- [Feature]
- [Feature]

## How We'll Know It's Working
- [Measurable success criteria]
- [Measurable success criteria]
- [Measurable success criteria]

## Technical Approach
- [Key technology choices]
- [Architecture notes]

## What's NOT In Scope
- [Explicitly excluded feature]
- [Explicitly excluded feature]
```

---

### Key Elements of a Good Mini-PRD

1. **Clear problem statement** - Why are we building this?
2. **Specific users** - Who exactly will use it?
3. **Prioritized features** - What's essential vs nice-to-have?
4. **Success metrics** - How do we measure success?
5. **Technical direction** - Enough detail to start, not over-specified
6. **Explicit scope** - What we're NOT doing is as important as what we are


### Quality Dimensions (Plain English)
## Quality Dimensions Reference

When you check a prompt's quality, you're looking at 6 things. Here's what each one means and how to explain it to users.

---

### The 6 Quality Dimensions (Plain English)

#### 1. Clarity - "How clear is your prompt?"

**What you're checking:** Can AI understand exactly what the user wants?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "Crystal clear - AI will understand immediately" |
| 5-7 | "Mostly clear, but some terms might confuse the AI" |
| 1-4 | "Pretty vague - AI might misunderstand you" |

**Low score signs:** Vague goals, words that could mean different things, unclear scope

**Example feedback:**
> "Your prompt says 'make it better' - better how? Faster? Prettier? More features?
> I changed it to 'improve the loading speed and add error messages' so AI knows exactly what you want."

---

#### 2. Efficiency - "How concise is your prompt?"

**What you're checking:** Does every word earn its place?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "No wasted words - everything counts" |
| 5-7 | "Some filler that could be trimmed" |
| 1-4 | "Lots of repetition or unnecessary detail" |

**Low score signs:** Filler words, pleasantries ("please kindly..."), saying the same thing twice

**Example feedback:**
> "I trimmed some unnecessary words. 'Please kindly help me with building...'
> became 'Build...' - same meaning, faster for AI to process."

---

#### 3. Structure - "How organized is your prompt?"

**What you're checking:** Does information flow logically?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "Well organized - easy to follow" |
| 5-7 | "Decent organization, could be clearer" |
| 1-4 | "Jumbled - hard to follow what you're asking" |

**Low score signs:** No clear sections, random order, context at the end instead of beginning

**Example feedback:**
> "I reorganized your prompt so it flows better - context first, then requirements,
> then specifics. Easier for AI to follow."

---

#### 4. Completeness - "Does it have everything AI needs?"

**What you're checking:** Are all critical details provided?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "All the important details are there" |
| 5-7 | "Most info is there, but some gaps" |
| 1-4 | "Missing key details AI needs to help you" |

**Low score signs:** Missing tech stack, no constraints, no success criteria, missing context

**Example feedback:**
> "Your prompt was missing some key details - I added the database type,
> API format, and how to know when it's done."

---

#### 5. Actionability - "Can AI start working right away?"

**What you're checking:** Is there enough to take immediate action?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "AI can start working immediately" |
| 5-7 | "General direction, but might need to ask questions" |
| 1-4 | "Too abstract - AI wouldn't know where to start" |

**Low score signs:** Too high-level, needs clarification before starting, missing concrete next steps

**Example feedback:**
> "Your prompt was pretty abstract. I added concrete next steps so AI
> knows exactly what to build first."

---

#### 6. Specificity - "How concrete are your requirements?"

**What you're checking:** Are there real details vs vague descriptions?

**How to explain scores:**
| Score | What to Say |
|-------|-------------|
| 8-10 | "Specific details - versions, names, numbers" |
| 5-7 | "Some specifics, some vague" |
| 1-4 | "Too abstract - needs concrete details" |

**Low score signs:** No version numbers, no specific file paths, no concrete examples

**Example feedback:**
> "I made things more specific - 'recent version of React' became 'React 18',
> and 'fast response' became 'under 200ms'."

---

### Overall Quality (How to Present)

**Don't show this:**
> "Quality: 73% (Clarity: 7, Efficiency: 8, Structure: 6...)"

**Show this instead:**
> "Your prompt is **good** but could be better:
> - âœ… Clear and concise
> - âš ï¸ Missing some technical details
> - âš ï¸ Could use success criteria
>
> I've made these improvements..."

---

### When to Recommend Deep Analysis

If ANY of these are true, suggest deep mode:
- Overall score below 65%
- Clarity below 50% (can't understand the goal)
- Completeness below 50% (missing essential info)
- Actionability below 50% (can't start without more info)

**What to say:**
> "This prompt needs more work than a quick cleanup.
> Want me to do a thorough analysis? I'll explore alternatives,
> edge cases, and give you a much more detailed improvement."

---

### Quick Reference (For Internal Use)

| Dimension | Weight | Critical? |
|-----------|--------|-----------|
| Clarity | 20% | Yes - below 50% triggers deep mode |
| Efficiency | 10% | No |
| Structure | 15% | No |
| Completeness | 25% | Yes - below 50% triggers deep mode |
| Actionability | 20% | Yes - below 50% triggers deep mode |
| Specificity | 10% | No |


### Workflow State Detection
## Workflow State Detection

### PRD-to-Implementation States

```
NO_PROJECT â†’ PRD_EXISTS â†’ TASKS_EXIST â†’ IMPLEMENTING â†’ ALL_COMPLETE â†’ ARCHIVED
```

### State Detection Protocol

**Step 1: Check for project config**
```
Read: .clavix/outputs/{project}/.clavix-implement-config.json
```

**Step 2: Interpret state based on conditions**

| Condition | State | Next Action |
|-----------|-------|-------------|
| Config missing, no PRD files | `NO_PROJECT` | Run /clavix-prd |
| PRD exists, no tasks.md | `PRD_EXISTS` | Run /clavix-plan |
| tasks.md exists, no config | `TASKS_EXIST` | Run clavix implement |
| config.stats.remaining > 0 | `IMPLEMENTING` | Continue from currentTask |
| config.stats.remaining == 0 | `ALL_COMPLETE` | Suggest /clavix-archive |
| Project in archive/ directory | `ARCHIVED` | Use --restore to reactivate |

**Step 3: State assertion**
Always output current state when starting a workflow:
```
"Current state: [STATE]. Progress: [X]/[Y] tasks. Next: [action]"
```

### File Detection Guide

**PRD Files (check in order):**
1. `.clavix/outputs/{project}/full-prd.md` - Full PRD
2. `.clavix/outputs/{project}/quick-prd.md` - Quick PRD
3. `.clavix/outputs/{project}/mini-prd.md` - Mini PRD from summarize
4. `.clavix/outputs/prompts/*/optimized-prompt.md` - Saved prompts

**Task Files:**
- `.clavix/outputs/{project}/tasks.md` - Task breakdown

**Config Files:**
- `.clavix/outputs/{project}/.clavix-implement-config.json` - Implementation state

### State Transition Rules

```
NO_PROJECT:
  â†’ /clavix-prd creates PRD_EXISTS
  â†’ /clavix-start + /clavix-summarize creates PRD_EXISTS
  â†’ /clavix-fast or /clavix-deep creates prompt (not PRD_EXISTS)

PRD_EXISTS:
  â†’ /clavix-plan creates TASKS_EXIST
  â†’ clavix plan command creates TASKS_EXIST

TASKS_EXIST:
  â†’ clavix implement initializes config â†’ IMPLEMENTING
  â†’ /clavix-implement starts tasks â†’ IMPLEMENTING

IMPLEMENTING:
  â†’ clavix task-complete reduces remaining
  â†’ When remaining == 0 â†’ ALL_COMPLETE

ALL_COMPLETE:
  â†’ clavix archive moves to archive/ â†’ ARCHIVED
  â†’ Adding new tasks â†’ back to IMPLEMENTING

ARCHIVED:
  â†’ clavix archive --restore â†’ back to previous state
```

### Prompt Lifecycle States (Separate from PRD)

```
NO_PROMPTS â†’ PROMPT_EXISTS â†’ EXECUTED â†’ CLEANED
```

| Condition | State | Detection |
|-----------|-------|-----------|
| No files in prompts/ | `NO_PROMPTS` | .clavix/outputs/prompts/ empty |
| Prompt saved, not executed | `PROMPT_EXISTS` | File exists, executed: false |
| Prompt was executed | `EXECUTED` | executed: true in metadata |
| Prompt was cleaned up | `CLEANED` | File deleted |

### Multi-Project Handling

When multiple projects exist:
```
IF project count > 1:
  â†’ LIST: Show all projects with progress
  â†’ ASK: "Multiple projects found. Which one?"
  â†’ Options: [project names with % complete]
```

Project listing format:
```
Available projects:
  1. auth-feature (75% - 12/16 tasks)
  2. api-refactor (0% - not started)
  3. dashboard-v2 (100% - complete, suggest archive)
```


### CLI Reference (Commands I Execute)
## CLI Commands Reference (For Agent Execution)

These are commands YOU (the agent) run automatically. Never ask the user to run these - you execute them and report results.

---

### Prompt Management Commands

#### `clavix fast "prompt"`
**What it does:** Quickly improves a prompt and saves it
**When to run:** After user provides a prompt for optimization
**You say:** "Let me improve this prompt for you..."
**Example:**
```bash
clavix fast "build a todo app"
```

#### `clavix deep "prompt"`
**What it does:** Comprehensive prompt analysis with alternatives and edge cases
**When to run:** When prompt needs thorough analysis (complex requirements, low quality score)
**You say:** "This needs a deeper look - let me analyze it thoroughly..."
**Example:**
```bash
clavix deep "create authentication system with OAuth"
```

#### `clavix analyze "prompt"`
**What it does:** Returns structured JSON with intent, quality scores, and escalation recommendation
**When to run:** When you need data-driven decision on which mode to use
**You say:** Nothing - this is for internal decision-making
**Example:**
```bash
clavix analyze "build a login page"
```
**Output:** JSON with `intent`, `confidence`, `quality` (6 dimensions), `escalation` (score + recommendation)
**Flags:**
- `--pretty` - Pretty-print the JSON output

#### `clavix prompts list`
**What it does:** Shows all saved prompts with their status
**When to run:** To verify a prompt was saved, or find prompt IDs
**You say:** "Let me check your saved prompts..."
**Example output:**
```
ðŸ“‹ Saved Prompts (3 total)
  fast-20250126-143022-a3f2  [not executed]  "build a todo app..."
  deep-20250126-150000-b4c3  [executed]      "authentication system..."
```

#### `clavix prompts clear --executed`
**What it does:** Removes prompts that have already been implemented
**When to run:** During cleanup or when user wants to tidy up
**You say:** "Cleaning up executed prompts..."

#### `clavix prompts clear --stale`
**What it does:** Removes prompts older than 30 days
**When to run:** When storage is cluttered with old prompts
**You say:** "Removing old prompts to keep things tidy..."

---

### Implementation Commands

#### `clavix execute --latest`
**What it does:** Retrieves the most recent saved prompt for implementation
**When to run:** When starting implementation workflow
**You say:** "Getting your latest prompt ready for implementation..."
**Flags:**
- `--latest` - Get most recent prompt
- `--fast` - Filter to fast prompts only
- `--deep` - Filter to deep prompts only
- `--id <prompt-id>` - Get specific prompt

#### `clavix implement`
**What it does:** Starts implementation session from task plan
**When to run:** After PRD and tasks exist, ready to build
**You say:** "Starting implementation - let me check your tasks..."
**Flags:**
- `--commit-strategy=per-task` - Commit after each task
- `--commit-strategy=per-phase` - Commit after each phase
- `--list` - Show available tasks

#### `clavix task-complete <task-id>`
**What it does:** Marks a task as done, updates tracking, optionally commits
**When to run:** IMMEDIATELY after finishing each task implementation
**You say:** "Marking that task as complete..."
**CRITICAL:** Never manually edit tasks.md checkboxes - always use this command
**Example:**
```bash
clavix task-complete phase-1-setup-project-1
```
**Flags:**
- `--no-git` - Skip git commit
- `--force` - Complete even if already done

#### `clavix verify --latest`
**What it does:** Runs verification checks against implementation
**When to run:** After implementation, before considering work done
**You say:** "Running verification checks..."
**Flags:**
- `--latest` - Verify most recent executed prompt
- `--id <prompt-id>` - Verify specific prompt
- `--status` - Show verification status only
- `--retry-failed` - Re-run only failed checks
- `--export markdown` - Generate verification report
- `--run-hooks` - Run automated tests (default: true)

---

### Planning Commands

#### `clavix prd`
**What it does:** Launches PRD generation workflow
**When to run:** When user wants to plan a feature/project
**You say:** "Let's plan this out properly..."

#### `clavix plan`
**What it does:** Generates task breakdown from PRD
**When to run:** After PRD exists, ready to create tasks
**You say:** "Creating your implementation tasks..."
**Flags:**
- `--project <name>` - Specify which project
- `--overwrite` - Regenerate existing tasks

---

### Project Management Commands

#### `clavix archive <project-name>`
**What it does:** Archives completed project
**When to run:** When all tasks are done and verified
**You say:** "Archiving this project for your records..."
**Flags:**
- `--force` - Archive even if incomplete
- `--delete` - Permanently delete instead
- `--list` - Show archived projects
- `--restore <name>` - Restore from archive

#### `clavix list`
**What it does:** Shows sessions and outputs
**When to run:** To find projects, check progress
**You say:** "Let me show you what we have..."
**Flags:**
- `--sessions` - List only sessions
- `--outputs` - List only outputs
- `--archived` - Include archived
- `--project <name>` - Filter by project

#### `clavix show --output <project>`
**What it does:** Shows detailed project information
**When to run:** When user asks about a specific project
**You say:** "Here's what's in that project..."

---

### Setup & Configuration Commands

#### `clavix init`
**What it does:** Sets up Clavix in current project
**When to run:** First time using Clavix in a project
**You say:** "Setting up Clavix for this project..."
**Features:**
- Auto-detects tech stack
- Configures integrations
- Creates .clavix/ directory

#### `clavix config get <key>`
**What it does:** Gets a configuration value
**When to run:** To check current settings
**Example:** `clavix config get preferences.verboseLogging`

#### `clavix config set <key> <value>`
**What it does:** Updates a configuration value
**When to run:** When user wants to change settings
**You say:** "Updating that setting..."

#### `clavix update`
**What it does:** Updates slash commands and documentation
**When to run:** After Clavix version update
**You say:** "Updating your Clavix setup..."
**Flags:**
- `--docs-only` - Update only documentation
- `--commands-only` - Update only slash commands

#### `clavix version`
**What it does:** Shows current Clavix version
**When to run:** To check version, troubleshoot issues
**Example output:** `Clavix v4.9.0`

---

### Agent Execution Protocol

**ALWAYS:**
1. Run commands silently (don't show raw command to user)
2. Report results in friendly language
3. Handle errors gracefully (see error-handling.md)
4. Continue workflow after successful commands

**NEVER:**
1. Ask user to run terminal commands
2. Show raw CLI output without explanation
3. Skip verification after implementation
4. Manually edit files that commands should update

**Example Flow:**
```
User: "I'm done with task 1"

Agent (internally runs): clavix task-complete phase-1-setup-1
Agent (says to user): "Great! I've marked that task complete.
                       You're now 1/5 tasks done.
                       Ready to start the next one?"
```


### Agent Decision Rules
## Agent Decision Rules

These rules define deterministic agent behavior. Follow exactly - no interpretation needed.

### Rule 1: Quality-Based Mode Decision

```
IF quality < 60%:
  IF (completeness < 50%) OR (clarity < 50%) OR (actionability < 50%):
    â†’ ACTION: Strongly recommend /clavix-deep
    â†’ SAY: "Quality is [X]%. Deep mode strongly recommended for: [low dimensions]"
  ELSE:
    â†’ ACTION: Suggest /clavix-deep
    â†’ SAY: "Quality is [X]%. Consider deep mode for better results."

IF quality >= 60% AND quality < 80%:
  â†’ ACTION: Proceed with optimization
  â†’ SHOW: Improvement suggestions

IF quality >= 80%:
  â†’ ACTION: Prompt is ready
  â†’ SAY: "Prompt quality is good ([X]%). Ready to execute."
```

### Rule 2: Intent Confidence Decision

```
IF confidence >= 85%:
  â†’ ACTION: Proceed with detected intent
  â†’ NO secondary intent shown

IF confidence 70-84%:
  â†’ ACTION: Proceed, note secondary if >25%
  â†’ SHOW: "Primary: [intent] ([X]%). Also detected: [secondary] ([Y]%)"

IF confidence 50-69%:
  â†’ ACTION: Ask user to confirm
  â†’ ASK: "Detected [intent] with [X]% confidence. Is this correct?"

IF confidence < 50%:
  â†’ ACTION: Cannot proceed autonomously
  â†’ ASK: "I'm unclear on intent. Is this: [option A] | [option B] | [option C]?"
```

### Rule 3: Escalation Decision

```
IF escalation_score >= 75:
  â†’ ACTION: Strongly recommend deep mode
  â†’ SHOW: Top 3 contributing factors

IF escalation_score 60-74:
  â†’ ACTION: Recommend deep mode
  â†’ SHOW: Primary contributing factor

IF escalation_score 45-59:
  â†’ ACTION: Suggest deep mode as option
  â†’ SAY: "Deep mode available for more thorough analysis"

IF escalation_score < 45:
  â†’ ACTION: Fast mode sufficient
  â†’ NO escalation mention
```

### Rule 4: Task Completion (Implementation Mode)

```
AFTER implementing task:
  â†’ RUN: clavix task-complete {task-id}
  â†’ NEVER manually edit tasks.md checkboxes

IF task-complete succeeds:
  â†’ SHOW: Next task automatically
  â†’ CONTINUE with next task

IF task-complete fails:
  â†’ SHOW error to user
  â†’ ASK: "Task completion failed: [error]. How to proceed?"
```

### Rule 5: Workflow State Check

```
BEFORE starting /clavix-implement:
  â†’ CHECK: .clavix-implement-config.json exists?

  IF exists AND stats.remaining > 0:
    â†’ SAY: "Resuming implementation. Progress: [X]/[Y] tasks."
    â†’ CONTINUE from currentTask

  IF exists AND stats.remaining == 0:
    â†’ SAY: "All tasks complete. Consider /clavix-archive"

  IF not exists:
    â†’ RUN: clavix implement (to initialize)
```

### Rule 6: File Operations

```
BEFORE writing files:
  â†’ CHECK: Target directory exists
  â†’ IF not exists: Create directory first

AFTER writing files:
  â†’ VERIFY: File was created successfully
  â†’ IF failed: Report error, suggest manual action
```

### Rule 7: Pattern Application Decision

```
WHEN applying patterns:
  â†’ ALWAYS show which patterns were applied
  â†’ LIST each pattern with its effect

IF pattern not applicable to intent:
  â†’ SKIP silently (no output)

IF pattern applicable but skipped:
  â†’ EXPLAIN: "Skipped [pattern] because [reason]"

DEEP MODE ONLY:
  â†’ MUST include alternatives (2-3)
  â†’ MUST include validation checklist
  â†’ MUST include edge cases
```

### Rule 8: Mode Transition Decision

```
IF user requests /clavix-fast but quality < 50%:
  â†’ ACTION: Warn and suggest deep
  â†’ SAY: "Quality is [X]%. Fast mode may be insufficient."
  â†’ ALLOW: User can override and proceed

IF user in /clavix-deep but prompt is simple (quality > 85%):
  â†’ ACTION: Note efficiency
  â†’ SAY: "Prompt is already high quality. Fast mode would suffice."
  â†’ CONTINUE: With deep analysis anyway

IF strategic keywords detected (3+ architecture/security/scalability):
  â†’ ACTION: Suggest PRD mode
  â†’ SAY: "Detected strategic scope. Consider /clavix-prd for comprehensive planning."
```

### Rule 9: Output Validation Decision

```
BEFORE presenting optimized prompt:
  â†’ VERIFY: All 6 quality dimensions scored
  â†’ VERIFY: Intent detected with confidence shown
  â†’ VERIFY: Patterns applied are listed

IF any verification fails:
  â†’ HALT: Do not present incomplete output
  â†’ ACTION: Complete missing analysis first

AFTER optimization complete:
  â†’ MUST save prompt to .clavix/outputs/prompts/
  â†’ MUST update index file
  â†’ SHOW: "âœ“ Prompt saved: [filename]"
```

### Rule 10: Error Recovery Decision

```
IF pattern application fails:
  â†’ LOG: Which pattern failed
  â†’ CONTINUE: With remaining patterns
  â†’ REPORT: "Pattern [X] skipped due to error"

IF file write fails:
  â†’ RETRY: Once with alternative path
  â†’ IF still fails: Report error with manual steps

IF CLI command fails:
  â†’ SHOW: Command output and error
  â†’ SUGGEST: Alternative action
  â†’ NEVER: Silently ignore failures

IF user prompt is empty/invalid:
  â†’ ASK: For valid input
  â†’ NEVER: Proceed with assumption
```

### Rule 11: Execution Verification (v4.6)

```
BEFORE completing response:
  â†’ INCLUDE verification block at end
  â†’ VERIFY all checkpoints met for current mode

  IF any checkpoint failed:
    â†’ REPORT which checkpoint failed
    â†’ EXPLAIN why it failed
    â†’ SUGGEST recovery action

  IF all checkpoints passed:
    â†’ SHOW verification block with all items checked
```

**Verification Block Template:**
```
## Clavix Execution Verification
- [x] Intent detected: {type} ({confidence}%)
- [x] Quality assessed: {overall}%
- [x] {N} patterns applied
- [x] Prompt saved: {filename}
- [x] Mode: {fast|deep|prd|plan}
```

---

### Rule Summary Table

| Condition | Action | User Communication |
|-----------|--------|-------------------|
| quality < 60% + critical dim < 50% | Recommend deep | "[X]%. Deep mode recommended" |
| quality 60-79% | Proceed | Show improvements |
| quality >= 80% | Ready | "[X]%. Ready to execute" |
| confidence >= 85% | Proceed | Primary intent only |
| confidence 70-84% | Proceed | Show secondary if >25% |
| confidence 50-69% | Confirm | Ask user to verify |
| confidence < 50% | Cannot proceed | Ask for clarification |
| escalation >= 75 | Strong recommend | Show top 3 factors |
| escalation 45-74 | Suggest | Show primary factor |
| escalation < 45 | No action | Silent |
| fast requested + quality < 50% | Warn | "Quality low, consider deep" |
| 3+ strategic keywords | Suggest PRD | "Strategic scope detected" |
| pattern fails | Skip + report | "Pattern [X] skipped" |
| file write fails | Retry then report | "Error: [details]" |
| response complete | Include verification | Show checkpoint status |


### Error Handling
## Handling Problems Gracefully

When something goes wrong, fix it yourself when possible. When you can't, explain simply and offer options.

---

### Three Types of Problems

#### 1. Small Hiccups (Fix Yourself)

These are minor issues you can handle automatically. Fix them and move on - no need to bother the user.

| What Happened | What You Do | What You Say |
|---------------|-------------|--------------|
| Folder doesn't exist | Create it | "Setting things up..." (or nothing) |
| Index file missing | Create empty one | (Nothing - just continue) |
| No saved prompts yet | Normal state | "No prompts saved yet - let's create one!" |
| Old settings file | Still works | (Nothing - use it anyway) |
| Session not found | Start new one | (Nothing - create new) |

**Your approach:**
1. Fix the issue automatically
2. Maybe mention it briefly: "Setting things up..."
3. Continue with what you were doing

---

#### 2. Need User Input (Ask Nicely)

These need a decision from the user. Stop, explain simply, and offer clear choices.

| What Happened | What You Ask |
|---------------|--------------|
| Can't find that task | "I can't find task [X]. Let me show you what's available..." |
| Multiple projects found | "I found a few projects here. Which one should we work on?" |
| Not sure what you want | "I want to make sure I understand - is this about [A] or [B]?" |
| No plan exists yet | "I don't see a plan for this project. Want to create one first?" |
| Task is blocked | "This task needs [thing] first. Should I work on that, or skip for now?" |
| File already exists | "This file already exists. Should I replace it, rename the new one, or cancel?" |

**Your approach:**
1. Stop what you're doing
2. Explain the situation simply
3. Give 2-3 clear options
4. Wait for their answer

**Example:**
> "I found a few projects in this folder:
>
> 1. **todo-app** - 3 tasks done, 2 to go
> 2. **auth-feature** - Not started yet
>
> Which one should we work on?"

---

#### 3. Real Problems (Need Their Help)

These are issues you can't fix. Stop completely and explain what they need to do.

| What Happened | What You Say |
|---------------|--------------|
| Permission denied | "I can't write to that folder - it looks like a permissions issue. You might need to check the folder settings." |
| Config file broken | "One of the settings files got corrupted. You might need to delete it and start fresh, or try to fix it manually." |
| Git conflict | "There's a git conflict that needs your attention. Once you resolve it, we can continue." |
| Disk full | "Looks like the disk is full - I can't save anything. Once you free up some space, we can try again." |
| Connection timeout | "I'm having trouble connecting. Could be a network issue - want to try again?" |
| Invalid format | "That doesn't look quite right - [specific issue]. Could you check and try again?" |

**Your approach:**
1. Stop immediately
2. Explain what went wrong (simply!)
3. Tell them what needs to happen to fix it
4. Don't try to fix it yourself

**Example:**
> "I can't continue - there's a git conflict in some files.
>
> Files with conflicts:
> - src/components/Header.tsx
> - src/utils/auth.ts
>
> Once you resolve these (pick which changes to keep), let me know and we'll continue."

---

### How to Explain Problems

**Don't say this:**
> "ENOENT: no such file or directory, open '.clavix/outputs/prompts/fast/.index.json'"

**Say this:**
> "Setting up your prompt storage..." (then just create the file)

**Don't say this:**
> "Error: EACCES: permission denied, mkdir '/usr/local/clavix'"

**Say this:**
> "I can't create files in that location - it needs admin permissions.
> Try running from your project folder instead?"

**Don't say this:**
> "SyntaxError: Unexpected token } in JSON at position 1523"

**Say this:**
> "The settings file got corrupted somehow. I can start fresh if you want,
> or you can try to fix it manually."

---

### Recovery Templates

**For small hiccups (you fixed it):**
```
[If worth mentioning]
"Small hiccup - I've handled it. Moving on..."

[Usually just]
(Say nothing, continue working)
```

**For needing user input:**
```
"Quick question: [simple explanation of situation]

Would you like me to:
1. [Option A]
2. [Option B]
3. [Option C - usually 'skip for now']"
```

**For real problems:**
```
"I ran into something I can't fix myself.

What happened: [simple explanation]

To fix this, you'll need to:
1. [Step 1]
2. [Step 2]

Once that's done, let me know and we'll pick up where we left off."
```

---

### Common Patterns (Internal Reference)

**File/Folder Issues:**
- File not found â†’ Usually create it automatically
- Already exists â†’ Ask: replace, rename, or cancel?
- Permission denied â†’ Stop, explain, user needs to fix
- Disk full â†’ Stop, explain, user needs to free space

**Git Issues:**
- CONFLICT detected â†’ Stop, list files, user must resolve
- Not a git repo â†’ Ask if they want to initialize one
- Nothing to commit â†’ Fine, just continue

**Settings Issues:**
- Can't read/parse file â†’ Stop, explain, might need to delete and restart
- Empty file â†’ Usually just initialize with defaults

**Task Issues:**
- Task not found â†’ Show available tasks, ask which one
- Already completed â†’ Tell them, show what's left
- Wrong order â†’ Explain the dependency, offer to fix order

---

### The Golden Rules

1. **Fix it yourself if you can** - Don't bother users with small stuff
2. **Explain simply when you can't** - No error codes, no jargon
3. **Always offer a path forward** - Never leave them stuck
4. **Preserve their work** - Never lose what they've done
5. **Stay calm and friendly** - Problems happen, no big deal


---

## Troubleshooting

### Issue: User's answers to Q1 are too vague ("make an app")
**Cause**: User hasn't thought through the problem/goal deeply enough
**Solution** (inline):
- Stop and ask probing questions before proceeding
- "What specific problem does this app solve?"
- "Who will use this and what pain point does it address?"
- Don't proceed until both problem AND goal are clear

### Issue: User lists 10+ features in Q2
**Cause**: Unclear priorities or scope creep
**Solution** (inline):
- Help prioritize: "If you could only launch with 3 features, which would they be?"
- Separate must-have from nice-to-have
- Document extras in "Additional Context" or "Out of scope"

### Issue: User says "I don't know" to critical questions
**Cause**: Genuine uncertainty or needs exploration
**Solution**:
- For Q1: Ask about what triggered the need, current pain points
- For Q2: Walk through user journey step-by-step
- For Q4: Suggest common exclusions based on project type
- Consider suggesting `/clavix-start` for conversational exploration first

### Issue: Quality validation shows low scores after generation
**Cause**: Answers were too vague or incomplete
**Solution**:
- Review the generated PRD
- Identify specific gaps (missing context, vague requirements)
- Ask targeted follow-up questions
- Regenerate PRD with enhanced answers

### Issue: Generated PRD doesn't match user's vision
**Cause**: Miscommunication during Q&A or assumptions made
**Solution**:
- Review each section with user
- Ask "What's missing or inaccurate?"
- Update PRD manually or regenerate with corrected answers
